{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING DATABASE: ./Rating_1.xlsx\n",
      "READING DATABASE: ./Rating_3.xlsx\n",
      "READING DATABASE: ./Rating_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "big_df = pd.DataFrame() \n",
    "    \n",
    "for filename in glob.glob(\"./Rating_*.xlsx\"):\n",
    "#    connres.commit()\n",
    "    print (\"READING DATABASE: \"+filename)\n",
    "    df = pd.read_excel(open(filename,'rb'), sheet_name=\"Resultados\",header = None) #Reading SABI Export without index  \n",
    "    df.columns = ['id', 'nombre_x', 'nif', 'nombre', 'provincia', 'calle', 'telefono', 'web', 'desc_actividad', 'cnae', 'cod_consolidacion', 'rating_grade_h2', 'rating_grade_h1', 'rating_grade_h0', 'rating_numerico_h2', 'rating_numerico_h1', 'rating_numerico_h0', 'modelo_propension_h2', 'modelo_propension_h1', 'modelo_propension_h0', 'guo_nombre', 'guo_id_bvd', 'guo_pais', 'guo_tipo', 'estado_detallado', 'fecha_cambio_estado', 'fecha_constitucion', 'p10000_h0', 'p10000_h1', 'p10000_h2', 'p20000_h0', 'p20000_h1', 'p20000_h2', 'p31200_h0', 'p31200_h1', 'p31200_h2', 'p32300_h0', 'p32300_h1', 'p32300_h2', 'p40100_mas_40500_h0', 'p40100_mas_40500_h1', 'p40100_mas_40500_h2', 'p40800_h0', 'p40800_h1', 'p40800_h2', 'p49100_h0', 'p49100_h1', 'p49100_h2']\n",
    "    df['h0_anio'] = 2017     \n",
    "    df = df.fillna('')\n",
    "    df=df.drop(df.index[0]) #Dropping SABI variable names.\n",
    "    df['nif'] = df.nif.str.upper() #CONVERTING cif INTO UPPERCASE\n",
    "    for partida in ['p10000_h0', 'p10000_h1', 'p10000_h2', 'p20000_h0', 'p20000_h1', 'p20000_h2', 'p31200_h0', 'p31200_h1', 'p31200_h2', 'p32300_h0', 'p32300_h1', 'p32300_h2', 'p40100_mas_40500_h0', 'p40100_mas_40500_h1', 'p40100_mas_40500_h2', 'p40800_h0', 'p40800_h1', 'p40800_h2', 'p49100_h0', 'p49100_h1', 'p49100_h2']:\n",
    "#        print (partida,\"ha sido convertido en numerico\")\n",
    "        df[partida] = pd.to_numeric(df[partida], errors='coerce').fillna(0)- 0.005\n",
    "    df['nif_normalizado'] = df['nif'].str[-8:]    \n",
    "    big_df = big_df.append(df, ignore_index=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Transformer that extracts columns passed as argument to its constructor \n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
    "\n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "    \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):\n",
    "        \n",
    "        X.loc[:, \"sector\"] = X.cnae.str[:2]\n",
    "        X.drop(columns = [\"cnae\"], inplace = True)\n",
    "        return X.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X['ebitda_income'] = (X.p49100_h1+X.p40800_h1)/(X.p40100_mas_40500_h1) \n",
    "        X['debt_ebitda'] =(X.p31200_h1 + X.p32300_h1) /(X.p49100_h1+X.p40800_h1) \n",
    "        X['rraa_rrpp'] = (X.p10000_h1 - X.p20000_h1) /X.p20000_h1\n",
    "        X['log_operating_income'] = np.log(X.p40100_mas_40500_h1)\n",
    "        X = X[['ebitda_income','debt_ebitda','rraa_rrpp','log_operating_income']]\n",
    "        X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categrical features to pass down the categorical pipeline \n",
    "categorical_features = [\"cnae\"]\n",
    "\n",
    "#Numerical features to pass down the numerical pipeline \n",
    "numerical_features = [\"p49100_h1\", \"p40800_h1\", \"p40100_mas_40500_h1\", \"p31200_h1\", \"p32300_h1\", \"p10000_h1\", \n",
    "                      \"p20000_h1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline = Pipeline( steps = [ ( 'cat_selector', FeatureSelector(categorical_features) ),\n",
    "                                  \n",
    "                                  ( 'cat_transformer', CategoricalTransformer() ), \n",
    "                                  \n",
    "                                  ( 'one_hot_encoder', OneHotEncoder( sparse = False ) ) ] )\n",
    "\n",
    "numerical_pipeline = Pipeline( steps = [ ( 'num_selector', FeatureSelector(numerical_features) ),\n",
    "                                  \n",
    "                                  ('imputer', SimpleImputer(strategy = 'median') ),\n",
    "                                  \n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'categorical_pipeline', categorical_pipeline ), \n",
    "                                                  \n",
    "                                                  ( 'numerical_pipeline', numerical_pipeline ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = big_df\n",
    "df['target_status'] = [0 if i in ['Activa', ''] else 1 for i in df['estado_detallado']] # 0 si Activa, 1 si algo raro!\n",
    "\n",
    "\n",
    "X = df.drop(columns = \"target_status\")\n",
    "y = df['target_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2 , random_state = 42 )\n",
    "\n",
    "\n",
    "#The full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  \n",
    "                                  ( 'model', RandomForestClassifier() ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = full_pipeline_m.fit(X, y)\n",
    "y_pred = fitted_model.predict(X)\n",
    "y_pred_proba = fitted_model.predict_proba(X)[:,1]\n",
    "\n",
    "print (\"ASSESSING THE MODEL...\")\n",
    "# CALCULATING GINI PERFORMANCE ON DEVELOPMENT SAMPLE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "gini_score = 2*roc_auc_score(y, y_pred_proba)-1\n",
    "print (\"GINI DEVELOPMENT=\", gini_score)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: {0}\".format(accuracy_score(y_pred,y)))\n",
    "\n",
    "print (\"SAVING THE PERSISTENT MODEL...\")\n",
    "from joblib import dump#, load\n",
    "dump(fitted_model, 'Rating_RandomForestClassifier.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
